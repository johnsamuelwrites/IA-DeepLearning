{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95de5d1-0a86-4166-9470-f14e5cf4f363",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3620593-8ba6-40e5-ac54-5b6f03ada38e",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410ecca-f096-4855-b7f7-0299fd6b6e2b",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fca6a1-a808-40b6-a856-d99bd51ab286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf028271-fc22-4fff-8782-a10aa7ec2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données d'exemple\n",
    "data = \"This is a class. This is a table\"\n",
    "\n",
    "# Prétraitement des données en utilisant nltk pour obtenir des phrases et des mots\n",
    "sentences = [word_tokenize(sentence.lower()) for sentence in sent_tokenize(data)]\n",
    "\n",
    "# Construction du modèle CBOW avec Gensim\n",
    "# min_count: Ignorer tous les mots dont la fréquence totale est inférieure à cette valeur.\n",
    "# size: Dimension des embeddings de mots\n",
    "# window: Distance maximale entre le mot courant et le mot prédit dans une phrase\n",
    "cbow_model = gensim.models.Word2Vec(sentences, min_count=1, vector_size=100, window=3, sg=0)\n",
    "\n",
    "# Affichage du vecteur du mot \"this\"\n",
    "print(\"Vecteur du mot 'this':\", cbow_model.wv[\"this\"])\n",
    "\n",
    "# Similarité entre les mots \"this\" et \"class\"\n",
    "print(\"Similarité entre 'this' et 'class':\", cbow_model.wv.similarity(\"this\", \"class\"))\n",
    "\n",
    "# Prédiction des deux mots les plus probables suivant le mot \"is\"\n",
    "predicted_words = cbow_model.wv.most_similar(positive=[\"is\"], topn=2)\n",
    "print(\"Prédiction des mots suivant 'is':\", predicted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3def8e-0d64-43dd-9a22-ed6ad25033ae",
   "metadata": {},
   "source": [
    "### Skip-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b30bf-d18b-4704-9e8a-0f507bdd34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895cad1-7559-4015-9ab9-4d3a73f437e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données d'exemple\n",
    "data = \"This is a class. This is a table\"\n",
    "\n",
    "# Prétraitement des données en utilisant nltk pour obtenir des phrases et des mots\n",
    "sentences = [word_tokenize(sentence.lower()) for sentence in sent_tokenize(data)]\n",
    "\n",
    "# Construction du modèle Skip-gram avec Gensim\n",
    "# min_count: Ignorer tous les mots dont la fréquence totale est inférieure à cette valeur.\n",
    "# size: Dimension des embeddings de mots\n",
    "# window: Distance maximale entre le mot courant et le mot prédit dans une phrase\n",
    "# sg: 1 pour skip-gram ; sinon CBOW.\n",
    "skipgram_model = gensim.models.Word2Vec(sentences, min_count=1, vector_size=100, window=5, sg=1)\n",
    "\n",
    "# Affichage du vecteur du mot \"this\"\n",
    "print(\"Vecteur du mot 'this':\", skipgram_model.wv[\"this\"])\n",
    "\n",
    "# Similarité entre les mots \"this\" et \"class\"\n",
    "print(\"Similarité entre 'this' et 'class':\", skipgram_model.wv.similarity(\"this\", \"class\"))\n",
    "\n",
    "# Prédiction des deux mots les plus probables suivant le mot \"is\"\n",
    "predicted_words = skipgram_model.wv.most_similar(positive=[\"is\"], topn=2)\n",
    "print(\"Prédiction des mots suivant 'is':\", predicted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8fe93f-839c-4274-9e71-233d1f6c57a0",
   "metadata": {},
   "source": [
    "## Vectors (spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77edc23-16a7-4ed8-8ca5-9fe5080f9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe270ddd-13b8-43c0-9abb-1ab7460bce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Texte à analyser\n",
    "text_to_analyze = \"cat\"\n",
    "doc = nlp(text_to_analyze)\n",
    "\n",
    "# Imprimer les vecteurs de chaque jeton sur une seule ligne\n",
    "vector_list = [token.vector for token in doc]\n",
    "print(\"Vecteurs de '{}' : {}\".format(text_to_analyze, vector_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0243fb-a736-473a-92c2-c6c2f53711d4",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c2073-35cd-4682-83ae-dab98ef4e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Définir les mots à comparer\n",
    "words_to_compare = [\"dog\", \"cat\", \"apple\"]\n",
    "\n",
    "# Calculer la similarité entre les paires de mots\n",
    "for i in range(len(words_to_compare)):\n",
    "    for j in range(i + 1, len(words_to_compare)):\n",
    "        word1, word2 = words_to_compare[i], words_to_compare[j]\n",
    "        doc1, doc2 = nlp(word1), nlp(word2)\n",
    "        similarity_score = doc1.similarity(doc2)\n",
    "        print(\"Similarité ({} / {}): {:.4f}\".format(word1, word2, similarity_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
