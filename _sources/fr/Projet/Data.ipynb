{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff07686",
   "metadata": {},
   "source": [
    "# Loading Data and Data Processing\n",
    "\n",
    "There are different types of data that need to be loaded and processed.\n",
    "1. Texts\n",
    "  * CSV files\n",
    "  * Human readable textual files\n",
    "2. Images\n",
    "3. Audio\n",
    "\n",
    "Data may come from different sources:\n",
    "1. Locally available data\n",
    "2. URL of dataset\n",
    "3. Available datasets from Tensorflow and Kaggle\n",
    "4. Numpy and Pandas arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12cf55e",
   "metadata": {},
   "source": [
    "## Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86fa00d",
   "metadata": {},
   "source": [
    "### CSV files\n",
    "\n",
    "#### Loading CSV files\n",
    "\n",
    "In the following exercise, we see how data is obtained from a CSV file whose URL is known to us and loaded to Tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e186b9b",
   "metadata": {},
   "source": [
    "In the first approach, we will directly load the data from the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b48910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importing the pandas library\n",
    "\n",
    "csv_data = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aacd69",
   "metadata": {},
   "source": [
    "Print the values of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b0be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3e1a9",
   "metadata": {},
   "source": [
    "In the second approach, we will download the data to our disk and create a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5065ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils # We use utils for downloading the data\n",
    "\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\"\n",
    "\n",
    "dataset_dir = utils.get_file(origin=url, cache_dir=\"./\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d3ac7",
   "metadata": {},
   "source": [
    "Verify whether the file is downloaded. If the above download is complete, the data will be downloaded to the **datasets** directory in the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a714ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "files = list(listdir(\"./datasets\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv(\n",
    "    \"./datasets/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99708337",
   "metadata": {},
   "source": [
    "#### Preprocessing CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5720be",
   "metadata": {},
   "source": [
    "Suppose that our goal is to predict the age from the other features. \n",
    "\n",
    "We will first see the unique values of Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csv_data[\"Age\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9056fa",
   "metadata": {},
   "source": [
    "Now we will create separate dataframe for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = csv_data.copy()\n",
    "labels = features.pop('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd72565",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2e2fc",
   "metadata": {},
   "source": [
    "We see only numerical values in the features. We will now create a numpy array of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_features = np.array(features)\n",
    "\n",
    "print(np_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970750af",
   "metadata": {},
   "source": [
    "**Note** It is a good practice to normalize the data before training a tensorflow model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313968ca",
   "metadata": {},
   "source": [
    "We will use `Normalization` from `tensorflow` for this purpose. \n",
    "Note that the function `adopt` should be run only on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "normalize = layers.Normalization()\n",
    "\n",
    "\n",
    "normalize.adapt(np_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bf8d0",
   "metadata": {},
   "source": [
    "#### Using the data for training\n",
    "\n",
    "Now we are ready to progress with the training.\n",
    "We have the features and the labels ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building a model\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  normalize, ## Note the use of Normalization layer\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ba959",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting the training\n",
    "\n",
    "history = model.fit(np_features, labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0455ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'])\n",
    "plt.legend(['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d51af6",
   "metadata": {},
   "source": [
    "### Text files\n",
    "\n",
    "Now we will focus on the text files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f2858",
   "metadata": {},
   "source": [
    "We will use Stack Overflow dataset for this part.Note that this is a zipped .tar dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f409f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download, unzip and untar the dataset\n",
    "\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n",
    "\n",
    "dataset_dir = utils.get_file(\n",
    "    origin=url,\n",
    "    untar=True,\n",
    "    cache_dir='./datasets',\n",
    "    cache_subdir='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a89071",
   "metadata": {},
   "source": [
    "We will now see the contents of the downloaded file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0280da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "files = list(listdir(\"./datasets\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2592f",
   "metadata": {},
   "source": [
    "If the download is correctly done, we can see the `train` and `test` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973eb9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(listdir(\"./datasets/train\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d044e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(listdir(\"./datasets/train/javascript\"))\n",
    "print(files[:5]) # print the name of first five files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(listdir(\"./datasets/test\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3970e712",
   "metadata": {},
   "source": [
    "As we can see there are only two folders: `train` and `test`. It is a good practice to create datasets for training, validation and testing.\n",
    "\n",
    "In the following code, we load the training data from the `train` folder and use 20% of the data for validation.\n",
    "\n",
    "So far, we have loaded the complete data for training. We will now create batches of size 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "validation_size_percentage = 0.2 # To ensure 80:20 training:validation \n",
    "seed = 40 # To ensure proper shuffiling\n",
    "\n",
    "train_batch = utils.text_dataset_from_directory(\n",
    "    \"./datasets/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split= validation_size_percentage,\n",
    "    subset='training',\n",
    "    seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f2598",
   "metadata": {},
   "source": [
    "We will now see the details of data: text and the associated label using the first batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in train_batch.take(1): # Taking into consideration the first batch\n",
    "    for i in range(batch_size):\n",
    "        print(f'Label: {label_batch[i].numpy()} for the text: {text_batch[i].numpy()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb22fb22",
   "metadata": {},
   "source": [
    "But, you may have observed that the labels are not \n",
    "'csharp', 'python', 'java', 'javascript', but rather some numbers 0,1, 2, 3.\n",
    "\n",
    "Now, we will display the associated class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ad86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(train_batch.class_names):\n",
    "  print(\"Label\", i, \"corresponds to\", label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593531c6",
   "metadata": {},
   "source": [
    "Now, we will create the validation dataset. \n",
    "\n",
    "Recall that we used the value 'training' for the parameter subset. This time we will use the value 'validation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feefbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batch = utils.text_dataset_from_directory(\n",
    "    \"./datasets/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split= validation_size_percentage,\n",
    "    subset='validation',\n",
    "    seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2203979e",
   "metadata": {},
   "source": [
    "And finally, we will create the test batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69098b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = utils.text_dataset_from_directory(\n",
    "    \"./datasets/test\",\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbabce2",
   "metadata": {},
   "source": [
    "However, these datasets cannot be yet used for training, since we need vectors for working with Tensorflow. \n",
    "\n",
    "Our next goal is to convert the text data to associated vectors.\n",
    "\n",
    "We will use two approaches:\n",
    "1. Binary Vectorization (one-hot encoding)\n",
    "2. 'int' Vectorization (integer indices for each token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5c3e4",
   "metadata": {},
   "source": [
    "We will first start with **binary Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vocabulary_size = 10000\n",
    "\n",
    "binary_vectorize_layer = TextVectorization(\n",
    "    max_tokens=vocabulary_size,\n",
    "    output_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c719249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_batch.map(lambda text, labels: text)\n",
    "binary_vectorize_layer.adapt(train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b863fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in train_batch.take(1):\n",
    "    for i in range(1):\n",
    "        print(\"Text\", text_batch[0].numpy())\n",
    "        print(\"Label\", label_batch[0].numpy())\n",
    "        print(\"Binary Vectorization:\")\n",
    "        print(binary_vectorize_layer(text_batch[0])) # One-hot encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee794506",
   "metadata": {},
   "source": [
    "The above output corresponds to one-hot encoding value of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4707e37",
   "metadata": {},
   "source": [
    "We will first start with **'int' Vectorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9a9ef",
   "metadata": {},
   "source": [
    "Unlike 'Binary' Vectorization, we also need the maximum sequence length.\n",
    "\n",
    "Long texts will be truncated to this maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d18ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vocabulary_size = 10000\n",
    "max_sequence_length = 200\n",
    "\n",
    "int_vectorize_layer = TextVectorization(\n",
    "    max_tokens=vocabulary_size,\n",
    "    output_sequence_length=max_sequence_length,\n",
    "    output_mode='int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_batch.map(lambda text, labels: text)\n",
    "int_vectorize_layer.adapt(train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in train_batch.take(1):\n",
    "    for i in range(1):\n",
    "        print(\"Text\", text_batch[0].numpy())\n",
    "        print(\"Label\", label_batch[0].numpy())\n",
    "        print(\"Binary Vectorization:\")\n",
    "        print(int_vectorize_layer(text_batch[0])) # Check the length of the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107524c9",
   "metadata": {},
   "source": [
    "To understand what the above sequence signify, we will look up in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d62005",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in int_vectorize_layer(text_batch[0]):\n",
    "    print(f\"{i}: \", int_vectorize_layer.get_vocabulary()[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf8d40",
   "metadata": {},
   "source": [
    "Now, we create functions to apply binary or 'int' vectorization to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_vectorize(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return binary_vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da694e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_vectorize(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return int_vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_batch = train_batch.map(binary_vectorize)\n",
    "binary_validation_batch = validation_batch.map(binary_vectorize)\n",
    "binary_test_batch = test_batch.map(binary_vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770efcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_train_batch = train_batch.map(int_vectorize)\n",
    "int_validation_batch = validation_batch.map(int_vectorize)\n",
    "int_test_batch = test_batch.map(int_vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6115de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training using binary 'Vectors'\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "num_labels = 4\n",
    "binary_model = tf.keras.Sequential([layers.Dense(num_labels)])\n",
    "\n",
    "binary_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = binary_model.fit(\n",
    "    binary_train_batch, validation_data=binary_validation_batch, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c441f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binary_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 4\n",
    "vocab_size=vocabulary_size + 1\n",
    "\n",
    "int_model = tf.keras.Sequential([\n",
    "      layers.Embedding(vocab_size, 64, mask_zero=True),\n",
    "      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "      layers.GlobalMaxPooling1D(),\n",
    "      layers.Dense(num_labels)\n",
    "  ])\n",
    "\n",
    "int_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "history = int_model.fit(int_train_batch, validation_data=int_validation_batch, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ee3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0dfc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_loss, binary_accuracy = binary_model.evaluate(binary_test_batch)\n",
    "int_loss, int_accuracy = int_model.evaluate(int_test_batch)\n",
    "\n",
    "print(\"Binary model accuracy: {:2.2%}\".format(binary_accuracy))\n",
    "print(\"Int model accuracy: {:2.2%}\".format(int_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26804a",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86203b1",
   "metadata": {},
   "source": [
    "### Loading Image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=url,\n",
    "                                   cache_dir='./datasets',\n",
    "                                   cache_subdir='',\n",
    "                                   untar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dddcdb",
   "metadata": {},
   "source": [
    "We will now check the contents of the downloded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c46976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "files = list(listdir(\"./datasets\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(listdir(\"./datasets/flower_photos\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268ebe0",
   "metadata": {},
   "source": [
    "#### Image data processing for building Tensorflow models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f49f3",
   "metadata": {},
   "source": [
    "For the processing of images, we need the values of batch size and image size (height and weight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1757e",
   "metadata": {},
   "source": [
    "For preparing the batch, we make use of `image_dataset_from_directory`. Note the parameter `image_size`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a03a07",
   "metadata": {},
   "source": [
    "We will first create the training batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "validation_size_percentage = 0.2 # To ensure 80:20 training:validation \n",
    "seed = 40 # To ensure proper shuffiling\n",
    "\n",
    "train_batch = utils.image_dataset_from_directory(\n",
    "    \"./datasets/flower_photos\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split= validation_size_percentage,\n",
    "    subset='training',\n",
    "    image_size=(img_height, img_width),\n",
    "    seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915ea06",
   "metadata": {},
   "source": [
    "Next, we will first create the validation batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batch = utils.image_dataset_from_directory(\n",
    "    \"./datasets/flower_photos\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split= validation_size_percentage,\n",
    "    subset='validation',\n",
    "    image_size=(img_height, img_width),\n",
    "    seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7116c",
   "metadata": {},
   "source": [
    "Let's see how the class names have been identified by Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_batch.class_names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f72956d",
   "metadata": {},
   "source": [
    "Next, we will plot the images as well as their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_batch.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c853bf4",
   "metadata": {},
   "source": [
    "We will now see the details of the first image from a batch: the shape of the image as well as the shape of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_batch.take(1):\n",
    "    print(images[0].shape)\n",
    "    print(labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8c404",
   "metadata": {},
   "source": [
    "As we have seen before, it is very important to normalize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0fe24",
   "metadata": {},
   "source": [
    "We now create the normalized batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_batch = train_batch.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c2d8c",
   "metadata": {},
   "source": [
    "Let's now see some information from an image of a normalized batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in normalized_batch.take(1):\n",
    "    print(np.min(images[0]), np.max(images[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f5edce",
   "metadata": {},
   "source": [
    "We will now build a Tensorflow model for the image classification.\n",
    "\n",
    "We add a normalization later in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38cdd0b",
   "metadata": {},
   "source": [
    "We now perform the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a02df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  train_batch,\n",
    "  validation_data=validation_batch,\n",
    "  epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fd4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06282a9f",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21222c",
   "metadata": {},
   "source": [
    "### Loading Audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e51959",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\"\n",
    "data_dir = tf.keras.utils.get_file(origin=url,\n",
    "                                   cache_dir='./datasets',\n",
    "                                   cache_subdir='',\n",
    "                                   extract=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08795e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "files = list(listdir(\"./datasets\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35345de",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(listdir(\"./datasets/mini_speech_commands\"))\n",
    "commands = []\n",
    "for c in files:\n",
    "    if c != 'README.md':\n",
    "        commands.append(c)\n",
    "print(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c194ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "filenames = glob(\"./datasets/mini_speech_commands/*/*\")\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "print(f\"Number of examples: {len(filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = filenames[:6400]\n",
    "val_files = filenames[6400: 6400 + 800]\n",
    "test_files = filenames[-800:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b72a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = tf.io.read_file(train_files[0])\n",
    "test_audio, _ = tf.audio.decode_wav(contents=test_file)\n",
    "test_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd617b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "    audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "    return tf.squeeze(audio, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_label_from_filepath(file_path):\n",
    "    \n",
    "    parts = tf.strings.split(\n",
    "        input=file_path,\n",
    "        sep=os.path.sep)\n",
    "    print(parts[-2])\n",
    "    return(parts[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = get_label_from_filepath(train_files[0])\n",
    "print(type(t))\n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waveform_and_label(file_path):\n",
    "    print(t.numpy())\n",
    "    label = get_label_from_filepath(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = decode_audio(audio_binary)\n",
    "    return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b946687",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "\n",
    "waveform_ds = files_ds.map(\n",
    "    map_func=get_waveform_and_label,\n",
    "    num_parallel_calls=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rows = 3\n",
    "cols = 3\n",
    "n = rows * cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 12))\n",
    "\n",
    "for i, (audio, label) in enumerate(waveform_ds.take(n)):\n",
    "  r = i // cols\n",
    "  c = i % cols\n",
    "  ax = axes[r][c]\n",
    "  ax.plot(audio.numpy())\n",
    "  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "  label = label.numpy().decode('utf-8')\n",
    "  ax.set_title(label)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "  input_len = 16000\n",
    "  waveform = waveform[:input_len]\n",
    "  zero_padding = tf.zeros(\n",
    "      [16000] - tf.shape(waveform),\n",
    "      dtype=tf.float32)\n",
    "  # Cast the waveform tensors' dtype to float32.\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "  # clips are of the same length.\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=255, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "for waveform, label in waveform_ds.take(1):\n",
    "  label = label.numpy().decode('utf-8')\n",
    "  spectrogram = get_spectrogram(waveform)\n",
    "\n",
    "print('Label:', label)\n",
    "print('Waveform shape:', waveform.shape)\n",
    "print('Spectrogram shape:', spectrogram.shape)\n",
    "print('Audio playback')\n",
    "display.display(display.Audio(waveform, rate=16000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4843bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec, shading='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0, 16000])\n",
    "\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_and_label_id(audio, label):\n",
    "  spectrogram = get_spectrogram(audio)\n",
    "  label_id = tf.argmax(label == commands)\n",
    "  return spectrogram, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_ds = waveform_ds.map(\n",
    "  map_func=get_spectrogram_and_label_id,\n",
    "  num_parallel_calls=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ff940",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "n = rows*cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "\n",
    "for i, (spectrogram, label_id) in enumerate(spectrogram_ds.take(n)):\n",
    "  r = i // cols\n",
    "  c = i % cols\n",
    "  ax = axes[r][c]\n",
    "  plot_spectrogram(spectrogram.numpy(), ax)\n",
    "  ax.set_title(commands[label_id.numpy()])\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1dd998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(files):\n",
    "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "  output_ds = files_ds.map(\n",
    "      map_func=get_waveform_and_label,\n",
    "      num_parallel_calls=AUTOTUNE)\n",
    "  output_ds = output_ds.map(\n",
    "      map_func=get_spectrogram_and_label_id,\n",
    "      num_parallel_calls=AUTOTUNE)\n",
    "  return output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = spectrogram_ds\n",
    "val_ds = preprocess_dataset(val_files)\n",
    "test_ds = preprocess_dataset(test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946af2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58daafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for spectrogram, _ in spectrogram_ds.take(1):\n",
    "  input_shape = spectrogram.shape\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# Instantiate the `tf.keras.layers.Normalization` layer.\n",
    "norm_layer = layers.Normalization()\n",
    "# Fit the state of the layer to the spectrograms\n",
    "# with `Normalization.adapt`.\n",
    "norm_layer.adapt(data=spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    # Downsample the input.\n",
    "    layers.Resizing(32, 32),\n",
    "    # Normalize.\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d286b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = []\n",
    "test_labels = []\n",
    "\n",
    "for audio, label in test_ds:\n",
    "  test_audio.append(audio.numpy())\n",
    "  test_labels.append(label.numpy())\n",
    "\n",
    "test_audio = np.array(test_audio)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
    "y_true = test_labels\n",
    "\n",
    "test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Test set accuracy: {test_acc:.0%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=commands,\n",
    "            yticklabels=commands,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c872c",
   "metadata": {},
   "source": [
    "### References\n",
    "1. [Tensorflow: Load CSV data](https://www.tensorflow.org/tutorials/load_data/csv?hl=en)\n",
    "2. [Tensorflow: Load text](https://www.tensorflow.org/tutorials/load_data/text?hl=en])\n",
    "3. [tf.keras.utils.text_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/utils/text_dataset_from_directory)\n",
    "4. [tf.keras.utils.get_file](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file)\n",
    "5. [tf.keras.layers.TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization)\n",
    "6. [Load and preprocess images](https://www.tensorflow.org/tutorials/load_data/images?hl=en%5D)\n",
    "7. [Simple audio recognition: Recognizing keywords](https://www.tensorflow.org/tutorials/audio/simple_audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
