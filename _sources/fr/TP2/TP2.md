Année: 2021-2022
----------------

# Travaux pratiques 2

## Objectifs
1. Implémentation de Multilayer perceptron en Python
2. Analyses de textes
3. Modèles LSTM

## Exercice 2.1

Implémenter le perceptron à plusieurs couches en Python avec les caractéristiques suivantes
1. Fonction d'activation configurable
2. Nombre d'entrées configurables 
3. Nombre d'époques et taux de formation configurables
4. Effectuer des prévisions
5. Rétro-propagation du gradient

Tester votre modèle avec des fonctions simple.

Référence: [https://www.kaggle.com/vitorgamalemos/multilayer-perceptron-from-scratch/notebook](https://www.kaggle.com/vitorgamalemos/multilayer-perceptron-from-scratch/notebook)

## Exercice 2.2

Téléchargez une page HTML sur Internet (par ex, <https://en.wikipedia.org/wiki/Paris>).
Choisissez un long paragraphe de la page et effectuer les opérations suivantes

1.  Racinisation
2.  Étiquetage en parties du discours (PoS)
3.  Lemmatisation
4.  Analyse morphologique
5.  Reconnaissance d'entités nommées
6.  Word embeddings à l'aide de modèles Word2Vec (CPOW et Skip-gram)

Vous pouvez utiliser un ou plusieurs des packages suivants, dans la mesure du possible. Si
vous utilisez plus de deux packages, rédigez également un petit rapport sur la comparaison de vos résultats. 

1. nltk
2. spaCy
3. gensim
4. Tensorflow

## Exercice 2.3

### Modèles LSTM

**Prévision des séries temporelles avec les modèles LSTM** : Veuillez vérifier et lancer le code suivant
<https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/>

Observez comment les séquences sont générées dans ces exemples.

